{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7056ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ VISUALIZATION AGENT TESTING\n",
      "================================================================================\n",
      "\n",
      "üìã Initial State:\n",
      "   - User Query: Compare Random Forest, XGBoost, and LightGBM for NRx forecasting performance\n",
      "   - Comparison Type: performance\n",
      "   - Requires Visualization: True\n",
      "   - Analysis Results Keys: ['computed_metrics', 'raw_data', 'patterns', 'anomalies', 'statistical_summary', 'data_row_count']\n",
      "   - Data Row Count: 9\n",
      "\n",
      "================================================================================\n",
      "üé® STEP 1: GENERATING VISUALIZATION SPECIFICATIONS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Generated 3 Visualization Specification(s):\n",
      "\n",
      "üìä Spec 1:\n",
      "   - Type: None\n",
      "   - Title: None\n",
      "   - Data Key: None\n",
      "   - X-axis: None\n",
      "   - Y-axis: None\n",
      "   - Additional Params: None\n",
      "\n",
      "üìä Spec 2:\n",
      "   - Type: None\n",
      "   - Title: None\n",
      "   - Data Key: None\n",
      "   - X-axis: None\n",
      "   - Y-axis: None\n",
      "   - Additional Params: None\n",
      "\n",
      "üìä Spec 3:\n",
      "   - Type: None\n",
      "   - Title: None\n",
      "   - Data Key: None\n",
      "   - X-axis: None\n",
      "   - Y-axis: None\n",
      "   - Additional Params: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä STEP 2: RENDERING CHARTS\n",
      "================================================================================\n",
      "Rendering chart: None\n",
      "Data key: raw_data\n",
      "Data type: <class 'list'>\n",
      "DataFrame shape: (9, 3)\n",
      "DataFrame columns: ['model_name', 'metric_name', 'metric_value']\n",
      "Unknown chart type: None\n",
      "Failed to render chart: None\n",
      "Rendering chart: None\n",
      "Data key: raw_data\n",
      "Data type: <class 'list'>\n",
      "DataFrame shape: (9, 3)\n",
      "DataFrame columns: ['model_name', 'metric_name', 'metric_value']\n",
      "Unknown chart type: None\n",
      "Failed to render chart: None\n",
      "Rendering chart: None\n",
      "Data key: raw_data\n",
      "Data type: <class 'list'>\n",
      "DataFrame shape: (9, 3)\n",
      "DataFrame columns: ['model_name', 'metric_name', 'metric_value']\n",
      "Unknown chart type: None\n",
      "Failed to render chart: None\n",
      "Total charts rendered: 0\n",
      "\n",
      "‚ö†Ô∏è No charts were rendered.\n",
      "\n",
      "Debugging Info:\n",
      "  - visualization_specs exists: True\n",
      "  - Number of specs: 3\n",
      "  - analysis_results exists: True\n",
      "\n",
      "================================================================================\n",
      "üñºÔ∏è STEP 3: DISPLAYING CHARTS\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è No charts to display.\n",
      "\n",
      "Troubleshooting steps:\n",
      "1. Check if visualization_specs were generated\n",
      "2. Check if analysis_results has the correct data structure\n",
      "3. Look for errors in the rendering step above\n",
      "\n",
      "================================================================================\n",
      "üîß STEP 4: MANUAL CHART TEST (Bypass Agents)\n",
      "================================================================================\n",
      "\n",
      "Creating a simple bar chart directly from mock data...\n",
      "\n",
      "DataFrame shape: (9, 3)\n",
      "DataFrame columns: ['model_name', 'metric_name', 'metric_value']\n",
      "\n",
      "First few rows:\n",
      "      model_name metric_name  metric_value\n",
      "0  Random Forest        rmse         42.50\n",
      "1  Random Forest    r2_score          0.78\n",
      "2  Random Forest         mae         35.20\n",
      "3        XGBoost        rmse         38.20\n",
      "4        XGBoost    r2_score          0.82\n",
      "\n",
      "‚úÖ Manual chart created successfully!\n",
      "‚ùå Error creating manual chart: Mime type rendering requires nbformat>=4.2.0 but it is not installed\n",
      "\n",
      "================================================================================\n",
      "üìä TEST SUMMARY\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Visualization Specs Generated: 3\n",
      "‚úÖ Charts Rendered: 0\n",
      "‚úÖ Execution Path: visualization_spec ‚Üí visualization_rendering\n",
      "\n",
      "‚ö†Ô∏è TROUBLESHOOTING NEEDED\n",
      "\n",
      "Possible issues:\n",
      "1. LLM (Gemini) not generating proper visualization specs\n",
      "2. Data format mismatch in _render_chart function\n",
      "3. Missing GEMINI_API_KEY environment variable\n",
      "4. Analysis results structure doesn't match expected format\n",
      "\n",
      "Check the debug output above for specific error messages.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15176\\447822257.py\", line 233, in <module>\n",
      "    fig.show()\n",
      "  File \"c:\\Users\\Admin\\Documents\\GitHub\\analytics_chatbot\\.venv\\Lib\\site-packages\\plotly\\basedatatypes.py\", line 3420, in show\n",
      "    return pio.show(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\Documents\\GitHub\\analytics_chatbot\\.venv\\Lib\\site-packages\\plotly\\io\\_renderers.py\", line 415, in show\n",
      "    raise ValueError(\n",
      "ValueError: Mime type rendering requires nbformat>=4.2.0 but it is not installed\n"
     ]
    }
   ],
   "source": [
    "# --- üß† Visualization Agent Testing Notebook ---\n",
    "\n",
    "# ‚úÖ Step 0: Setup Environment (Run this first)\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure the project root is in the path\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# ‚úÖ Step 1: Imports\n",
    "from agent.nodes import (\n",
    "    visualization_specification_agent,\n",
    "    visualization_rendering_agent,\n",
    "    _render_chart  # Import the render function for direct testing\n",
    ")\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# ‚úÖ Step 2: Mock Analysis Results (Simulating output from analysis_computation_agent)\n",
    "# This simulates what the analysis_computation_agent would return\n",
    "\n",
    "# Create a more complete mock that matches what the agent actually produces\n",
    "mock_computed_metrics = {\n",
    "    \"rmse\": {\n",
    "        \"Random Forest\": 42.5,\n",
    "        \"XGBoost\": 38.2,\n",
    "        \"LightGBM\": 40.1\n",
    "    },\n",
    "    \"r2_score\": {\n",
    "        \"Random Forest\": 0.78,\n",
    "        \"XGBoost\": 0.82,\n",
    "        \"LightGBM\": 0.80\n",
    "    },\n",
    "    \"mae\": {\n",
    "        \"Random Forest\": 35.2,\n",
    "        \"XGBoost\": 31.8,\n",
    "        \"LightGBM\": 33.5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create raw data format (simulating SQL query results)\n",
    "mock_raw_data = [\n",
    "    {\n",
    "        \"success\": True,\n",
    "        \"data\": [\n",
    "            {\"model_name\": \"Random Forest\", \"metric_name\": \"rmse\", \"metric_value\": 42.5},\n",
    "            {\"model_name\": \"Random Forest\", \"metric_name\": \"r2_score\", \"metric_value\": 0.78},\n",
    "            {\"model_name\": \"Random Forest\", \"metric_name\": \"mae\", \"metric_value\": 35.2},\n",
    "            {\"model_name\": \"XGBoost\", \"metric_name\": \"rmse\", \"metric_value\": 38.2},\n",
    "            {\"model_name\": \"XGBoost\", \"metric_name\": \"r2_score\", \"metric_value\": 0.82},\n",
    "            {\"model_name\": \"XGBoost\", \"metric_name\": \"mae\", \"metric_value\": 31.8},\n",
    "            {\"model_name\": \"LightGBM\", \"metric_name\": \"rmse\", \"metric_value\": 40.1},\n",
    "            {\"model_name\": \"LightGBM\", \"metric_name\": \"r2_score\", \"metric_value\": 0.80},\n",
    "            {\"model_name\": \"LightGBM\", \"metric_name\": \"mae\", \"metric_value\": 33.5},\n",
    "        ],\n",
    "        \"row_count\": 9,\n",
    "        \"columns\": [\"model_name\", \"metric_name\", \"metric_value\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "mock_analysis_results = {\n",
    "    \"computed_metrics\": mock_computed_metrics,\n",
    "    \"raw_data\": mock_raw_data,\n",
    "    \"patterns\": [\n",
    "        \"XGBoost shows best performance across all metrics\",\n",
    "        \"Random Forest has highest RMSE indicating larger prediction errors\",\n",
    "        \"All models show good R¬≤ scores above 0.75\"\n",
    "    ],\n",
    "    \"anomalies\": [],\n",
    "    \"statistical_summary\": {\n",
    "        \"mean_rmse\": 40.3,\n",
    "        \"mean_r2\": 0.80,\n",
    "        \"mean_mae\": 33.5\n",
    "    },\n",
    "    \"data_row_count\": 9\n",
    "}\n",
    "\n",
    "# ‚úÖ Step 3: Initialize State\n",
    "state = {\n",
    "    \"user_query\": \"Compare Random Forest, XGBoost, and LightGBM for NRx forecasting performance\",\n",
    "    \"comparison_type\": \"performance\",\n",
    "    \"requires_visualization\": True,\n",
    "    \"analysis_results\": mock_analysis_results,\n",
    "    \"execution_path\": [],\n",
    "    \"models_requested\": [\"Random Forest\", \"XGBoost\", \"LightGBM\"],\n",
    "    \"use_case\": \"NRx_forecasting\"\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üß™ VISUALIZATION AGENT TESTING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìã Initial State:\")\n",
    "print(f\"   - User Query: {state['user_query']}\")\n",
    "print(f\"   - Comparison Type: {state['comparison_type']}\")\n",
    "print(f\"   - Requires Visualization: {state['requires_visualization']}\")\n",
    "print(f\"   - Analysis Results Keys: {list(state['analysis_results'].keys())}\")\n",
    "print(f\"   - Data Row Count: {state['analysis_results']['data_row_count']}\")\n",
    "\n",
    "# ‚úÖ Step 4: Run Visualization Specification Agent\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé® STEP 1: GENERATING VISUALIZATION SPECIFICATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    state_after_spec = visualization_specification_agent(state)\n",
    "    state.update(state_after_spec)\n",
    "    \n",
    "    viz_specs = state.get(\"visualization_specs\", [])\n",
    "    \n",
    "    if viz_specs:\n",
    "        print(f\"\\n‚úÖ Generated {len(viz_specs)} Visualization Specification(s):\\n\")\n",
    "        for i, spec in enumerate(viz_specs, 1):\n",
    "            print(f\"üìä Spec {i}:\")\n",
    "            print(f\"   - Type: {spec.get('type')}\")\n",
    "            print(f\"   - Title: {spec.get('title')}\")\n",
    "            print(f\"   - Data Key: {spec.get('data_key')}\")\n",
    "            print(f\"   - X-axis: {spec.get('x')}\")\n",
    "            print(f\"   - Y-axis: {spec.get('y')}\")\n",
    "            print(f\"   - Additional Params: {spec.get('additional_params')}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No visualization specs generated!\")\n",
    "        print(\"This might mean:\")\n",
    "        print(\"  - requires_visualization was False\")\n",
    "        print(\"  - LLM failed to generate specs\")\n",
    "        print(\"  - Error in visualization_specification_agent\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error in visualization_specification_agent:\")\n",
    "    print(f\"   {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ‚úÖ Step 5: Run Visualization Rendering Agent\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä STEP 2: RENDERING CHARTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    state_after_render = visualization_rendering_agent(state)\n",
    "    state.update(state_after_render)\n",
    "    \n",
    "    rendered_charts = state.get(\"rendered_charts\", [])\n",
    "    \n",
    "    if rendered_charts:\n",
    "        print(f\"\\n‚úÖ {len(rendered_charts)} Chart(s) Rendered Successfully!\\n\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No charts were rendered.\")\n",
    "        print(\"\\nDebugging Info:\")\n",
    "        print(f\"  - visualization_specs exists: {bool(state.get('visualization_specs'))}\")\n",
    "        print(f\"  - Number of specs: {len(state.get('visualization_specs', []))}\")\n",
    "        print(f\"  - analysis_results exists: {bool(state.get('analysis_results'))}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error in visualization_rendering_agent:\")\n",
    "    print(f\"   {type(e).__name__}: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ‚úÖ Step 6: Display the Charts\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üñºÔ∏è STEP 3: DISPLAYING CHARTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "rendered_charts = state.get(\"rendered_charts\", [])\n",
    "\n",
    "if rendered_charts:\n",
    "    for i, chart_data in enumerate(rendered_charts, 1):\n",
    "        title = chart_data.get(\"title\", f\"Chart {i}\")\n",
    "        chart_type = chart_data.get(\"type\", \"unknown\")\n",
    "        figure = chart_data.get(\"figure\")\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"üìà Chart {i}: {title} ({chart_type})\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        if figure:\n",
    "            try:\n",
    "                # In Jupyter, this will display inline\n",
    "                figure.show()\n",
    "                print(f\"\\n‚úÖ Chart displayed successfully\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error displaying chart: {e}\\n\")\n",
    "        else:\n",
    "            print(\"‚ùå No figure object found\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No charts to display.\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Check if visualization_specs were generated\")\n",
    "    print(\"2. Check if analysis_results has the correct data structure\")\n",
    "    print(\"3. Look for errors in the rendering step above\")\n",
    "\n",
    "# ‚úÖ Step 7: Manual Test - Create Chart Directly\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîß STEP 4: MANUAL CHART TEST (Bypass Agents)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Creating a simple bar chart directly from mock data...\\n\")\n",
    "\n",
    "try:\n",
    "    # Extract data from mock_raw_data\n",
    "    data_rows = mock_raw_data[0]['data']\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Create a simple bar chart\n",
    "    fig = px.bar(\n",
    "        df[df['metric_name'] == 'rmse'],\n",
    "        x='model_name',\n",
    "        y='metric_value',\n",
    "        title='Model Performance Comparison (RMSE)',\n",
    "        labels={'metric_value': 'RMSE', 'model_name': 'Model'},\n",
    "        color='model_name'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        height=400,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Manual chart created successfully!\")\n",
    "    fig.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating manual chart: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ‚úÖ Step 8: Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä TEST SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Visualization Specs Generated: {len(state.get('visualization_specs', []))}\")\n",
    "print(f\"‚úÖ Charts Rendered: {len(state.get('rendered_charts', []))}\")\n",
    "print(f\"‚úÖ Execution Path: {' ‚Üí '.join(state.get('execution_path', []))}\")\n",
    "\n",
    "if not state.get('rendered_charts'):\n",
    "    print(\"\\n‚ö†Ô∏è TROUBLESHOOTING NEEDED\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"1. LLM (Gemini) not generating proper visualization specs\")\n",
    "    print(\"2. Data format mismatch in _render_chart function\")\n",
    "    print(\"3. Missing GEMINI_API_KEY environment variable\")\n",
    "    print(\"4. Analysis results structure doesn't match expected format\")\n",
    "    print(\"\\nCheck the debug output above for specific error messages.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ALL TESTS PASSED!\")\n",
    "    print(\"Your visualization pipeline is working correctly.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
